Projeto Pedra Pagamentos

Este projeto tem como objetivo processar e gerenciar atendimentos e lotes processados utilizando Airflow, PostgreSQL e SQLAlchemy. 
Ele permite a automaÃ§Ã£o de tarefas relacionadas ao processamento de dados, armazenamento de informaÃ§Ãµes relevantes e geraÃ§Ã£o de GrÃ¡ficos.

ğŸ“Œ Tecnologias Utilizadas

Apache Airflow: OrquestraÃ§Ã£o de workflows

PostgreSQL: Banco de dados relacional

SQLAlchemy: ORM para interaÃ§Ã£o com o banco

Docker & Docker Compose: Gerenciamento de containers

ğŸš€ Como Executar o Projeto

1ï¸âƒ£ PrÃ©-requisitos

Certifique-se de ter instalado:

Docker

Docker Compose

Python versÃ£o 3.9 ou Superior

2ï¸âƒ£ Clonando o RepositÃ³rio

    git clone https://github.com/FilipeDeberge/pedra_pagamentos_pipeline.git
    cd pedra_pagamentos_pipeline

3ï¸âƒ£ Subindo os Containers

Para criar a imagem com as especificaÃ§Ãµes do DockerFile:
    docker-compose build --no-cache

Para subir os containers com suas respectivas definiÃ§Ãµes
    docker-compose up -d --build

Isso irÃ¡ iniciar os serviÃ§os do PostgreSQL e do Airflow.

4ï¸âƒ£ Acessando o Airflow

ApÃ³s a execuÃ§Ã£o, acesse o Airflow pelo navegador:

http://localhost:8080

Credenciais padrÃ£o:

UsuÃ¡rio: admin

Senha: admin

5ï¸âƒ£ CriaÃ§Ã£o o Banco e as Tabelas

Se o banco de dados e as tabelas nÃ£o existirem, eles serÃ£o criados automaticamente pelo entrypoint, que roda quando os containers sÃ£o carregados.


ğŸ“œ Estrutura do Projeto

â”œâ”€â”€ dags/                  # DAGs do Airflow
â”œâ”€â”€ dashboard/             # Dashboards gerados
â”‚   â”œâ”€â”€ gerar_graficos.py  # Script para geraÃ§Ã£o dos grÃ¡ficos baseados nas KPIs
â”œâ”€â”€ models/                # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ models.py          # DefiniÃ§Ã£o das tabelas
â”‚   â”œâ”€â”€ create_tables.sql  # Script SQL para criaÃ§Ã£o de tabelas
â”œâ”€â”€ airflow.cfg            # Arquivo de configuraÃ§Ã£o do airflow
â”œâ”€â”€ alembic.ini            # Arquivo de configuraÃ§Ã£o do alembic utilizado com o SQLAlchemy
â”œâ”€â”€ config.py              # ConfiguraÃ§Ã£o do banco de dados
â”œâ”€â”€ services.py            # Camada de serviÃ§os para centralizar as regras de negÃ³cio
â”œâ”€â”€ repositories.py        # Camada de repositÃ³rios para centralizar os fluxos no banco de dados
â”œâ”€â”€ export_dw.py           # Script para exportar dados para DW
â”œâ”€â”€ docker-compose.yml     # ConfiguraÃ§Ã£o do Docker
â”œâ”€â”€ entrypoint.sh          # Script de inicializaÃ§Ã£o
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto

âœ… PrÃ³ximos Passos

Configurar mais DAGs no Airflow para processamento automatizado

Implementar novos endpoints para interagir com os dados

Melhorar a gestÃ£o de logs e monitoramento

Caso tenha dÃºvidas, consulte a documentaÃ§Ã£o ou entre em contato! ğŸš€

